{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip uninstall tensorflow -y\n",
    "!pip install tensorflow==2.8.0\n",
    "!pip install tensorflow_addons==0.16.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python train.py --model_id 1 --train_dir=/content/drive/MyDrive/plant/train --val_dir=/content/drive/MyDrive/plant/val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Conv2D, Dense, LeakyReLU, Flatten, MaxPooling2D, Input\n",
    "\n",
    "# Util\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Train\n",
    "# import argparse\n",
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "# from utils import gen_maker, CustomCallback\n",
    "# from networks import model_maker\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "import tensorflow_addons as tfa\n",
    "import pickle as pkl\n",
    "\n",
    "# eval\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow_addons.optimizers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# networks.py\n",
    "\n",
    "def mlp(x, hidden_units, dropout_rate):\n",
    "    for units in hidden_units:\n",
    "        x = layers.Dense(units, activation=tf.nn.gelu)(x)\n",
    "    return x\n",
    "\n",
    "class Patches(layers.Layer):\n",
    "    def __init__(self, patch_size):\n",
    "        super(Patches, self).__init__()\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "    def call(self, images):\n",
    "        batch_size = tf.shape(images)[0]\n",
    "        patches = tf.image.extract_patches(\n",
    "            images=images,\n",
    "            sizes=[1, self.patch_size, self.patch_size, 1],\n",
    "            strides=[1, self.patch_size, self.patch_size, 1],\n",
    "            rates=[1, 1, 1, 1],\n",
    "            padding=\"VALID\",\n",
    "        )\n",
    "        patch_dims = patches.shape[-1]\n",
    "        patches = tf.reshape(patches, [batch_size, -1, patch_dims])\n",
    "        return patches\n",
    "\n",
    "class PatchEncoder(layers.Layer):\n",
    "    def __init__(self, num_patches, projection_dim):\n",
    "        super(PatchEncoder, self).__init__()\n",
    "        self.num_patches = num_patches\n",
    "        self.projection = layers.Dense(units=projection_dim)\n",
    "        self.position_embedding = layers.Embedding(\n",
    "            input_dim=num_patches, output_dim=projection_dim\n",
    "        )\n",
    "\n",
    "    def call(self, patch):\n",
    "        positions = tf.range(start=0, limit=self.num_patches, delta=1)\n",
    "        encoded = self.projection(patch) + self.position_embedding(positions)\n",
    "        return encoded\n",
    "\n",
    "def create_vit_classifier(input_shape, patch_size, num_patches, projection_dim, transformer_units, transformer_layers, model_name, num_heads, mlp_head_units, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(inputs)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    #representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    logits = layers.Dense(num_classes, activation = 'softmax')(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits, name = model_name)\n",
    "    return model\n",
    "\n",
    "def model_maker(target_size, model_id, num_classes = 3):\n",
    "    \"\"\" This function creates a trainable model. \n",
    "        params:\n",
    "            target_size: tuple, size of the input image to the network\n",
    "            model_id: integer, it can be 1 to 4\n",
    "        returns: \n",
    "            tensorflow trainable model.\n",
    "    \"\"\"\n",
    "\n",
    "    if model_id == 1:\n",
    "        inp = Input(shape = (*target_size, 3), name = 'input_layer')\n",
    "        cnv1 = Conv2D(filters = 10, kernel_size = (3, 3), strides = (1, 1), name = 'conv_1')(inp)\n",
    "        cnv2 = Conv2D(filters = 10, kernel_size = (3, 3), strides = (1, 1), name = 'conv_2')(cnv1)\n",
    "        mxp1 = MaxPooling2D(pool_size = (2, 2), strides= (2, 2), name = 'maxpool_1')(cnv2)\n",
    "        cnv3 = Conv2D(filters = 16, kernel_size = (3, 3), strides = (1, 1), name = 'conv_3')(mxp1)\n",
    "        cnv4 = Conv2D(filters = 16, kernel_size = (3, 3), strides = (1, 1), name = 'conv_4')(cnv3)\n",
    "        mxp2 = MaxPooling2D(pool_size = (2, 2), strides= (2, 2), name = 'maxpool_2')(cnv4)\n",
    "        fltn = Flatten(name = 'flatten_layer')(mxp2)\n",
    "        FC1 = Dense(50, name = 'FC_1')(fltn)\n",
    "        FC1 = LeakyReLU(alpha = 0.3, name = 'leaky_ReLu_1')(FC1)\n",
    "        FC2 = Dense(50, name = 'FC_2')(FC1)\n",
    "        FC2 = LeakyReLU(alpha = 0.3, name = 'leaky_ReLu_2')(FC2)\n",
    "        output = Dense(num_classes, activation = 'softmax', name = 'output_layer')(FC2)\n",
    "        model = Model(inputs = inp, outputs = output, name = 'WheatClassifier_CNN_'+str(model_id))\n",
    "        model.summary()\n",
    "    \n",
    "    if model_id == 2:\n",
    "        inp = Input(shape = (*target_size, 3), name = 'input_layer')\n",
    "        cnv1 = Conv2D(filters = 10, kernel_size = (3, 3), strides = (1, 1), name = 'conv_1')(inp)\n",
    "        cnv2 = Conv2D(filters = 10, kernel_size = (3, 3), strides = (1, 1), name = 'conv_2')(cnv1)\n",
    "        mxp1 = MaxPooling2D(pool_size = (2, 2), strides= (2, 2), name = 'maxpool_1')(cnv2)\n",
    "        cnv3 = Conv2D(filters = 16, kernel_size = (3, 3), strides = (1, 1), name = 'conv_3')(mxp1)\n",
    "        cnv4 = Conv2D(filters = 16, kernel_size = (3, 3), strides = (1, 1), name = 'conv_4')(cnv3)\n",
    "        mxp2 = MaxPooling2D(pool_size = (2, 2), strides= (2, 2), name = 'maxpool_2')(cnv4)\n",
    "        cnv5 = Conv2D(filters = 16, kernel_size = (3, 3), strides = (1, 1), name = 'conv_5')(mxp2)\n",
    "        cnv6 = Conv2D(filters = 16, kernel_size = (3, 3), strides = (1, 1), name = 'conv_6')(cnv5)\n",
    "        mxp3 = MaxPooling2D(pool_size = (2, 2), strides= (2, 2), name = 'maxpool_3')(cnv6)\n",
    "        fltn = Flatten(name = 'flatten_layer')(mxp3)\n",
    "        FC1 = Dense(50, name = 'FC_1')(fltn)\n",
    "        FC1 = LeakyReLU(alpha = 0.3, name = 'leaky_ReLu_1')(FC1)\n",
    "        FC2 = Dense(50, name = 'FC_2')(FC1)\n",
    "        FC2 = LeakyReLU(alpha = 0.3, name = 'leaky_ReLu_2')(FC2)\n",
    "        output = Dense(num_classes, activation = 'softmax', name = 'output_layer')(FC2)\n",
    "        model = Model(inputs = inp, outputs = output, name = 'WheatClassifier_CNN_'+str(model_id))\n",
    "        model.summary()\n",
    "\n",
    "    elif model_id == 3:\n",
    "        image_size = target_size[0]  # We'll resize input images to this size\n",
    "        patch_size = 10  # Size of the patches to be extract from the input images\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        projection_dim = 64\n",
    "        num_heads = 4\n",
    "        transformer_units = [\n",
    "            projection_dim * 2,\n",
    "            projection_dim]  # Size of the transformer layers\n",
    "        transformer_layers = 2\n",
    "        mlp_head_units = [50, 50]\n",
    "        model = create_vit_classifier((*target_size, 3),\n",
    "                                      patch_size,\n",
    "                                      num_patches,\n",
    "                                      projection_dim,\n",
    "                                      transformer_units,\n",
    "                                      transformer_layers, \n",
    "                                      'WheatClassifier_VIT_'+str(model_id),\n",
    "                                      num_heads, mlp_head_units, num_classes)\n",
    "        model.summary()\n",
    "        \n",
    "    elif model_id == 4:\n",
    "        image_size = target_size[0]  # We'll resize input images to this size\n",
    "        patch_size = 10  # Size of the patches to be extract from the input images\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        projection_dim = 64\n",
    "        num_heads = 4\n",
    "        transformer_units = [\n",
    "            projection_dim * 2,\n",
    "            projection_dim]  # Size of the transformer layers\n",
    "        transformer_layers = 4\n",
    "        mlp_head_units = [50, 50]\n",
    "        model = create_vit_classifier((*target_size, 3),\n",
    "                                      patch_size,\n",
    "                                      num_patches,\n",
    "                                      projection_dim,\n",
    "                                      transformer_units,\n",
    "                                      transformer_layers,\n",
    "                                      'WheatClassifier_VIT_'+str(model_id),\n",
    "                                      num_heads, mlp_head_units, num_classes)\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "    elif model_id == 5:\n",
    "        inp = Input(shape = (*target_size, 3), name = 'input_layer')\n",
    "        cnv1 = Conv2D(filters = 10, kernel_size = (3, 3), strides = (1, 1), name = 'conv_1')(inp)\n",
    "        cnv2 = Conv2D(filters = 10, kernel_size = (3, 3), strides = (1, 1), name = 'conv_2')(cnv1)\n",
    "        mxp1 = MaxPooling2D(pool_size = (2, 2), strides= (2, 2), name = 'maxpool_1')(cnv2)\n",
    "        size_mxp1 = getattr(mxp1, 'shape')\n",
    "        image_size =size_mxp1[1]  # We'll resize input images to this size\n",
    "        patch_size = 10  # Size of the patches to be extract from the input images\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        projection_dim = 64\n",
    "        num_heads = 4\n",
    "        transformer_units = [\n",
    "            projection_dim * 2,\n",
    "            projection_dim]  # Size of the transformer layers\n",
    "        transformer_layers = 1\n",
    "        mlp_head_units = [50, 50]\n",
    "        patches = Patches(patch_size)(mxp1)\n",
    "        # Encode patches.\n",
    "        encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "        # Create multiple layers of the Transformer block.\n",
    "        for _ in range(transformer_layers):\n",
    "            # Layer normalization 1.\n",
    "            x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "            # Create a multi-head attention layer.\n",
    "            attention_output = layers.MultiHeadAttention(\n",
    "                num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "            )(x1, x1)\n",
    "            # Skip connection 1.\n",
    "            x2 = layers.Add()([attention_output, encoded_patches])\n",
    "            # Layer normalization 2.\n",
    "            x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "            # MLP.\n",
    "            x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "            # Skip connection 2.\n",
    "            encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "        # Create a [batch_size, projection_dim] tensor.\n",
    "        representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "        fltn = Flatten(name = 'flatten_layer')(representation)\n",
    "        FC1 = Dense(50, name = 'FC_1')(fltn)\n",
    "        FC1 = LeakyReLU(alpha = 0.3, name = 'leaky_ReLu_1')(FC1)\n",
    "        FC2 = Dense(50, name = 'FC_2')(FC1)\n",
    "        FC2 = LeakyReLU(alpha = 0.3, name = 'leaky_ReLu_2')(FC2)\n",
    "        output = Dense(num_classes, activation = 'softmax', name = 'output_layer')(FC2)\n",
    "        model = Model(inputs = inp, outputs = output, name = 'WheatClassifier_CNN_'+str(model_id))\n",
    "        model.summary()\n",
    "\n",
    "    elif model_id == 6:\n",
    "        inp = Input(shape = (*target_size, 3), name = 'input_layer')\n",
    "        cnv1 = Conv2D(filters = 10, kernel_size = (3, 3), strides = (1, 1), name = 'conv_1')(inp)\n",
    "        cnv2 = Conv2D(filters = 10, kernel_size = (3, 3), strides = (1, 1), name = 'conv_2')(cnv1)\n",
    "        mxp1 = MaxPooling2D(pool_size = (2, 2), strides= (2, 2), name = 'maxpool_1')(cnv2)\n",
    "        cnv3 = Conv2D(filters = 16, kernel_size = (3, 3), strides = (1, 1), name = 'conv_3')(mxp1)\n",
    "        cnv4 = Conv2D(filters = 16, kernel_size = (3, 3), strides = (1, 1), name = 'conv_4')(cnv3)\n",
    "        mxp2 = MaxPooling2D(pool_size = (2, 2), strides= (2, 2), name = 'maxpool_2')(cnv4)\n",
    "        size_mxp2 = getattr(mxp2, 'shape')\n",
    "        image_size =size_mxp2[1]  # We'll resize input images to this size\n",
    "        patch_size = 5  # Size of the patches to be extract from the input images\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        print(num_patches, patch_size, image_size)\n",
    "        projection_dim = 64\n",
    "        num_heads = 4\n",
    "        transformer_units = [\n",
    "          projection_dim * 2,\n",
    "          projection_dim]  # Size of the transformer layers\n",
    "        transformer_layers = 2\n",
    "        mlp_head_units = [50, 50]\n",
    "        patches = Patches(patch_size)(mxp2)\n",
    "      # Encode patches.\n",
    "        encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "      # Create multiple layers of the Transformer block.\n",
    "        for _ in range(transformer_layers):\n",
    "          # Layer normalization 1.\n",
    "            x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "          # Create a multi-head attention layer.\n",
    "            attention_output = layers.MultiHeadAttention(\n",
    "              num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "            )(x1, x1)\n",
    "          # Skip connection 1.\n",
    "            x2 = layers.Add()([attention_output, encoded_patches])\n",
    "          # Layer normalization 2.\n",
    "            x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "          # MLP.\n",
    "            x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "          # Skip connection 2.\n",
    "            encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "      # Create a [batch_size, projection_dim] tensor.\n",
    "        representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "\n",
    "        fltn = Flatten(name = 'flatten_layer')(representation)\n",
    "        FC1 = Dense(50, name = 'FC_1')(fltn)\n",
    "        FC1 = LeakyReLU(alpha = 0.3, name = 'leaky_ReLu_1')(FC1)\n",
    "        FC2 = Dense(50, name = 'FC_2')(FC1)\n",
    "        FC2 = LeakyReLU(alpha = 0.3, name = 'leaky_ReLu_2')(FC2)\n",
    "        output = Dense(num_classes, activation = 'softmax', name = 'output_layer')(FC2)\n",
    "        model = Model(inputs = inp, outputs = output, name = 'WheatClassifier_CNN-VIT_'+str(model_id))\n",
    "        model.summary()\n",
    "\n",
    "    elif model_id == 7:\n",
    "        image_size = target_size[0]  # We'll resize input images to this size\n",
    "        patch_size = 10  # Size of the patches to be extract from the input images\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        projection_dim = 64\n",
    "        num_heads = 4\n",
    "        transformer_units = [\n",
    "          projection_dim * 2,\n",
    "          projection_dim]  # Size of the transformer layers\n",
    "        transformer_layers = 1\n",
    "        mlp_head_units = [50, 50]\n",
    "        inputs = layers.Input(shape = (*target_size, 3), name = 'input_layer')\n",
    "      # Create patches.\n",
    "        patches = Patches(patch_size)(inputs)\n",
    "\n",
    "      # Encode patches.\n",
    "        encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "      # Create multiple layers of the Transformer block.\n",
    "        for _ in range(transformer_layers):\n",
    "          # Layer normalization 1.\n",
    "            x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "          # Create a multi-head attention layer.\n",
    "            attention_output = layers.MultiHeadAttention(\n",
    "              num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "          )(x1, x1)\n",
    "          # Skip connection 1.\n",
    "            x2 = layers.Add()([attention_output, encoded_patches])\n",
    "          # Layer normalization 2.\n",
    "            x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "          # MLP.\n",
    "            x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "          # Skip connection 2.\n",
    "            encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "      # Create a [batch_size, projection_dim] tensor.\n",
    "        representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        size_rep = getattr(representation, 'shape')\n",
    "\n",
    "        representation = tf.keras.layers.Reshape((int(size_rep[1]**0.5), int(size_rep[1]**0.5), size_rep[2]))(representation)\n",
    "        cnv1 = Conv2D(filters = 10, kernel_size = (3, 3), strides = (1, 1), name = 'conv_1')(representation)\n",
    "        cnv2 = Conv2D(filters = 10, kernel_size = (3, 3), strides = (1, 1), name = 'conv_2')(cnv1)\n",
    "        if int(size_rep[1]**0.5)>5:\n",
    "            mxp1 = MaxPooling2D(pool_size = (2, 2), strides= (2, 2), name = 'maxpool_1')(cnv2)\n",
    "\n",
    "            fltn = Flatten(name = 'flatten_layer')(mxp1)\n",
    "        else:\n",
    "            fltn = Flatten(name = 'flatten_layer')(cnv2)\n",
    "        FC1 = Dense(50, name = 'FC_1')(fltn)\n",
    "        FC1 = LeakyReLU(alpha = 0.3, name = 'leaky_ReLu_1')(FC1)\n",
    "        FC2 = Dense(50, name = 'FC_2')(FC1)\n",
    "        FC2 = LeakyReLU(alpha = 0.3, name = 'leaky_ReLu_2')(FC2)\n",
    "        output = Dense(num_classes, activation = 'softmax', name = 'output_layer')(FC2)\n",
    "        model = Model(inputs = inputs, outputs = output, name = 'WheatClassifier_CNN_'+str(1))\n",
    "        model.summary()\n",
    "\n",
    "    elif model_id == 8:\n",
    "        image_size = target_size[0]  # We'll resize input images to this size\n",
    "        patch_size = 10  # Size of the patches to be extract from the input images\n",
    "        num_patches = (image_size // patch_size) ** 2\n",
    "        projection_dim = 64\n",
    "        num_heads = 4\n",
    "        transformer_units = [\n",
    "          projection_dim * 2,\n",
    "          projection_dim]  # Size of the transformer layers\n",
    "        transformer_layers = 2\n",
    "        mlp_head_units = [50, 50]\n",
    "        inputs = layers.Input(shape = (*target_size, 3), name = 'input_layer')\n",
    "      # Create patches.\n",
    "        patches = Patches(patch_size)(inputs)\n",
    "\n",
    "      # Encode patches.\n",
    "        encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "      # Create multiple layers of the Transformer block.\n",
    "        for _ in range(transformer_layers):\n",
    "          # Layer normalization 1.\n",
    "            x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "          # Create a multi-head attention layer.\n",
    "            attention_output = layers.MultiHeadAttention(\n",
    "              num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "            )(x1, x1)\n",
    "          # Skip connection 1.\n",
    "            x2 = layers.Add()([attention_output, encoded_patches])\n",
    "          # Layer normalization 2.\n",
    "            x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "          # MLP.\n",
    "            x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "          # Skip connection 2.\n",
    "            encoded_patches = layers.Add()([x3, x2])\n",
    "\n",
    "      # Create a [batch_size, projection_dim] tensor.\n",
    "        representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        size_rep = getattr(representation, 'shape')\n",
    "\n",
    "        representation = tf.keras.layers.Reshape((int(size_rep[1]**0.5), int(size_rep[1]**0.5), size_rep[2]))(representation)\n",
    "        if int(size_rep[1]**0.5)==5:\n",
    "            cnv1 = Conv2D(filters = 10, kernel_size = (3, 3), strides = (1, 1), name = 'conv_1', padding = 'same')(representation)\n",
    "            cnv2 = Conv2D(filters = 10, kernel_size = (3, 3), strides = (1, 1), name = 'conv_2', padding = 'same')(cnv1)\n",
    "            #mxp1 = MaxPooling2D(pool_size = (2, 2), strides= (2, 2), name = 'maxpool_1')(cnv2)\n",
    "\n",
    "            cnv3 = Conv2D(filters = 16, kernel_size = (3, 3), strides = (1, 1), name = 'conv_3', padding = 'valid')(cnv2)\n",
    "            cnv4 = Conv2D(filters = 16, kernel_size = (3, 3), strides = (1, 1), name = 'conv_4', padding = 'valid')(cnv3)\n",
    "            #mxp2 = MaxPooling2D(pool_size = (2, 2), strides= (2, 2), name = 'maxpool_2')(cnv4)\n",
    "              \n",
    "\n",
    "            fltn = Flatten(name = 'flatten_layer')(cnv4)\n",
    "        elif int(size_rep[1]**0.5)==10:\n",
    "            cnv1 = Conv2D(filters = 10, kernel_size = (3, 3), strides = (1, 1), name = 'conv_1', padding = 'valid')(representation)\n",
    "            cnv2 = Conv2D(filters = 10, kernel_size = (3, 3), strides = (1, 1), name = 'conv_2', padding = 'valid')(cnv1)\n",
    "            #mxp1 = MaxPooling2D(pool_size = (2, 2), strides= (2, 2), name = 'maxpool_1')(cnv2)\n",
    "\n",
    "            cnv3 = Conv2D(filters = 16, kernel_size = (3, 3), strides = (1, 1), name = 'conv_3', padding = 'valid')(cnv2)\n",
    "            cnv4 = Conv2D(filters = 16, kernel_size = (3, 3), strides = (1, 1), name = 'conv_4', padding = 'valid')(cnv3)\n",
    "            #mxp2 = MaxPooling2D(pool_size = (2, 2), strides= (2, 2), name = 'maxpool_2')(cnv4)\n",
    "              \n",
    "\n",
    "            fltn = Flatten(name = 'flatten_layer')(cnv4)\n",
    "        else:\n",
    "            cnv1 = Conv2D(filters = 10, kernel_size = (3, 3), strides = (1, 1), name = 'conv_1', padding = 'valid')(representation)\n",
    "            cnv2 = Conv2D(filters = 10, kernel_size = (3, 3), strides = (1, 1), name = 'conv_2', padding = 'valid')(cnv1)\n",
    "            mxp1 = MaxPooling2D(pool_size = (2, 2), strides= (2, 2), name = 'maxpool_1')(cnv2)\n",
    "\n",
    "            cnv3 = Conv2D(filters = 16, kernel_size = (3, 3), strides = (1, 1), name = 'conv_3', padding = 'valid')(mxp1)\n",
    "            cnv4 = Conv2D(filters = 16, kernel_size = (3, 3), strides = (1, 1), name = 'conv_4', padding = 'valid')(cnv3)\n",
    "            mxp2 = MaxPooling2D(pool_size = (2, 2), strides= (2, 2), name = 'maxpool_2')(cnv4)\n",
    "              \n",
    "\n",
    "            fltn = Flatten(name = 'flatten_layer')(mxp2)\n",
    "\n",
    "        FC1 = Dense(50, name = 'FC_1')(fltn)\n",
    "        FC1 = LeakyReLU(alpha = 0.3, name = 'leaky_ReLu_1')(FC1)\n",
    "        FC2 = Dense(50, name = 'FC_2')(FC1)\n",
    "        FC2 = LeakyReLU(alpha = 0.3, name = 'leaky_ReLu_2')(FC2)\n",
    "        output = Dense(num_classes, activation = 'softmax', name = 'output_layer')(FC2)\n",
    "        model = Model(inputs = inputs, outputs = output, name = 'WheatClassifier_CNN_'+str(1))\n",
    "        model.summary()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "def gen_maker(train_path, val_path, target_size=(100, 100), batch_size=16, mode='categorical'):\n",
    "    \"\"\"\n",
    "    This function creates data generators for train and validation data.\n",
    "    params:\n",
    "        train_path: path to the training data folder, string.\n",
    "        val_path: path to the validation data folder, string. \n",
    "        target_size: size of the inputs to the network, tuple.\n",
    "        batch_size: the batch size for training and validation, integer. \n",
    "        mode: classification mode, it can be either \"binary\" or \"categorical\"\n",
    "    returns:\n",
    "        train_generator: data generator for training data.\n",
    "        validation_generator: data generator for validation data.\n",
    "    \"\"\"\n",
    "\n",
    "    train_datagen = ImageDataGenerator( rotation_range=10,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.2,\n",
    "                                    shear_range=0.1,\n",
    "                                    zoom_range=0.1,\n",
    "                                    channel_shift_range=0.0,\n",
    "                                    horizontal_flip=True,\n",
    "                                    vertical_flip=True,\n",
    "                                    rescale=1./255)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,  \n",
    "        target_size=target_size,  \n",
    "        batch_size=batch_size,\n",
    "        class_mode=mode)  \n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        val_path,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        class_mode=mode)\n",
    "    return train_generator, validation_generator\n",
    "\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    This callback saves the model at the end of each epoch and calculates\n",
    "    the confusion matrix and classification report on the validation data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, val_gen, model_path, model_id):\n",
    "        \n",
    "        super(CustomCallback, self).__init__()\n",
    "        self.val_gen = val_gen\n",
    "        self.model_path = model_path\n",
    "        self.model_id = model_id\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.model.save(self.model_path + 'epoch{}-id{}'.format(epoch,self.model_id ))\n",
    "        y_pred = self.model.predict(self.val_gen)\n",
    "        y_pred = np.squeeze(np.argmax(y_pred, axis = 1))\n",
    "        y_true = self.val_gen.classes\n",
    "        cnf = confusion_matrix(y_true, y_pred)\n",
    "        cls_report = classification_report(y_true, y_pred)\n",
    "        print('\\nclassification report:\\n', cls_report)\n",
    "        print('\\nconfusion matrix:\\n', cnf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_maker(train_path, val_path, target_size=(100, 100), batch_size=16, mode='categorical'):\n",
    "    \"\"\"\n",
    "    This function creates data generators for train and validation data.\n",
    "    params:\n",
    "        train_path: path to the training data folder, string.\n",
    "        val_path: path to the validation data folder, string. \n",
    "        target_size: size of the inputs to the network, tuple.\n",
    "        batch_size: the batch size for training and validation, integer. \n",
    "        mode: classification mode, it can be either \"binary\" or \"categorical\"\n",
    "    returns:\n",
    "        train_generator: data generator for training data.\n",
    "        validation_generator: data generator for validation data.\n",
    "    \"\"\"\n",
    "\n",
    "    train_datagen = ImageDataGenerator( rotation_range=10,\n",
    "                                    width_shift_range=0.2,\n",
    "                                    height_shift_range=0.2,\n",
    "                                    shear_range=0.1,\n",
    "                                    zoom_range=0.1,\n",
    "                                    channel_shift_range=0.0,\n",
    "                                    horizontal_flip=True,\n",
    "                                    vertical_flip=True,\n",
    "                                    rescale=1./255)\n",
    "\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,  \n",
    "        target_size=target_size,  \n",
    "        batch_size=batch_size,\n",
    "        class_mode=mode)  \n",
    "\n",
    "    validation_generator = test_datagen.flow_from_directory(\n",
    "        val_path,\n",
    "        target_size=target_size,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        class_mode=mode)\n",
    "    return train_generator, validation_generator\n",
    "\n",
    "class CustomCallback(tf.keras.callbacks.Callback):\n",
    "    \"\"\"\n",
    "    This callback saves the model at the end of each epoch and calculates\n",
    "    the confusion matrix and classification report on the validation data.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, val_gen, model_path, model_id):\n",
    "        \n",
    "        super(CustomCallback, self).__init__()\n",
    "        self.val_gen = val_gen\n",
    "        self.model_path = model_path\n",
    "        self.model_id = model_id\n",
    "        \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        self.model.save(self.model_path + 'epoch{}-id{}'.format(epoch,self.model_id ))\n",
    "        y_pred = self.model.predict(self.val_gen)\n",
    "        y_pred = np.squeeze(np.argmax(y_pred, axis = 1))\n",
    "        y_true = self.val_gen.classes\n",
    "        cnf = confusion_matrix(y_true, y_pred)\n",
    "        cls_report = classification_report(y_true, y_pred)\n",
    "        print('\\nclassification report:\\n', cls_report)\n",
    "        print('\\nconfusion matrix:\\n', cnf)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100                # Number of total epochs\n",
    "init_epoch = 0              # Initial epoch\n",
    "train_dir = '/content/train/'  # Training data folder path\n",
    "val_dir = '/content/val/'      # Validation data folder path\n",
    "model_id = 1                # Model ID: it can be 1, 2, 3, or 4\n",
    "load_model = 0              # If 1, load a previously trained model\n",
    "load_path = None            # Path to the pre-trained model\n",
    "backup_path = '/content/'   # Path to store the model\n",
    "batch_size = 16             # Batch size for training\n",
    "mode = 'categorical'        # Classification mode\n",
    "target_size = 100           # Size of the input images\n",
    "\n",
    "# Define the main training function\n",
    "def main():\n",
    "\n",
    "    # Generate training and validation datasets\n",
    "    train_gen, val_gen = gen_maker(\n",
    "        train_dir, \n",
    "        val_dir, \n",
    "        target_size=(target_size, target_size), \n",
    "        batch_size=batch_size, \n",
    "        mode=mode\n",
    "    )\n",
    "    \n",
    "    # Custom callback\n",
    "    clbk = CustomCallback(val_gen, backup_path, model_id)\n",
    "    \n",
    "    # Set learning rate and weight decay\n",
    "    learning_rate = 0.001\n",
    "    weight_decay = 0.0001\n",
    "    \n",
    "    # Create the model\n",
    "    model = model_maker((target_size, target_size), model_id)\n",
    "    \n",
    "    # Set up optimizer\n",
    "    optimizer = tfa.optimizers.AdamW(\n",
    "        learning_rate=learning_rate, \n",
    "        weight_decay=weight_decay\n",
    "    )\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=categorical_crossentropy,\n",
    "        metrics=['acc']\n",
    "    )\n",
    "    \n",
    "    # Load pre-trained model if specified\n",
    "    if load_model:\n",
    "        model = tf.keras.models.load_model(load_path)\n",
    "    \n",
    "    # Train the model\n",
    "    results = model.fit(\n",
    "        train_gen,\n",
    "        epochs=epochs,\n",
    "        validation_data=val_gen,\n",
    "        callbacks=[clbk], \n",
    "        initial_epoch=init_epoch\n",
    "    )\n",
    "\n",
    "    # Predict validation data\n",
    "    y_pred_valid = model.predict(val_gen)\n",
    "\n",
    "    # Save history and model\n",
    "    history = {\n",
    "        'train loss': results.history['loss'],\n",
    "        'val loss': results.history['val_loss'], \n",
    "        'train acc': results.history['acc'],\n",
    "        'val acc': results.history['val_acc'],\n",
    "        'y_true_valid': val_gen.classes,\n",
    "        'y_pred_valid': y_pred_valid, \n",
    "        'id': model_id\n",
    "    }\n",
    "    model.save(f\"{backup_path}model.h5\")\n",
    "\n",
    "    with open(f\"{backup_path}history-id-{model_id}.pkl\", 'wb') as f:\n",
    "        pkl.dump(history, f)\n",
    "\n",
    "    # Plot training and validation metrics\n",
    "    plt.subplots(figsize=(15, 15))\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(results.history['loss'], '-', color=[0, 0, 1, 1])\n",
    "    plt.plot(results.history['val_loss'], '-', color=[1, 0, 0, 1])\n",
    "    plt.legend(['train loss', 'val loss'])\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot([0, *results.history['acc']], '-', color=[0, 0, 1, 1])\n",
    "    plt.plot([0, *results.history['val_acc']], '-', color=[1, 0, 0, 1])\n",
    "    plt.legend(['train acc', 'val acc'])\n",
    "    \n",
    "    plt.savefig(f\"{backup_path}charts.png\")\n",
    "\n",
    "# Run main function\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE THE MODEL\n",
    "\n",
    "# Load the model with the custom optimizer specified\n",
    "model = tf.keras.models.load_model('/content/model.h5', custom_objects={'AdamW': AdamW})\n",
    "\n",
    "# Load and preprocess a single image\n",
    "img_path = '/content/drive/MyDrive/plant/val/Brown_rust/Brown_rust036.jpg'\n",
    "img = image.load_img(img_path, target_size=(100, 100))  # Resize as per model input\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension\n",
    "img_array = img_array / 255.0  # Normalize if necessary\n",
    "\n",
    "# Predict the class of the image\n",
    "predictions = model.predict(img_array)\n",
    "predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "print(\"Predicted class:\", predicted_class)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
